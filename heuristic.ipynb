{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/vincentzhao/Desktop/Project_Master/heuristic.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentzhao/Desktop/Project_Master/heuristic.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#基础+动态闸值+水平不重合文本不合并+nlp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vincentzhao/Desktop/Project_Master/heuristic.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentzhao/Desktop/Project_Master/heuristic.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertTokenizer, BertForNextSentencePrediction, BertModel\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vincentzhao/Desktop/Project_Master/heuristic.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpairwise\u001b[39;00m \u001b[39mimport\u001b[39;00m cosine_similarity\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#基础+动态闸值+水平不重合文本不合并+nlp\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pdf2image import convert_from_path\n",
    "import easyocr\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "# 初始化BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "nsp_model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 初始化OCR阅读器\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# 将PDF转换为图像\n",
    "pdf_path = '/Users/zhoushengfang/Desktop/毕业论文/cct-linked-structured-note.pdf'\n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "# 在第一页图像上执行OCR\n",
    "bounds = reader.readtext(np.array(images[0]), min_size=10, slope_ths=0.5, ycenter_ths=0.7, height_ths=1.2, width_ths=0.85, decoder='beamsearch', beamWidth=10)\n",
    "\n",
    "# 获取句子表示\n",
    "def get_sentence_embedding(sentence, max_length=512):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "    outputs = bert_model(**inputs)\n",
    "    cls_embedding = outputs.last_hidden_state[0, 0, :].detach().numpy()\n",
    "    return cls_embedding\n",
    "\n",
    "# NSP预测\n",
    "def nsp_predict(sentence_a, sentence_b, max_length=512):\n",
    "    inputs = tokenizer(sentence_a, sentence_b, return_tensors='pt', truncation=True, max_length=max_length)\n",
    "    outputs = nsp_model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    return probs[0][0].item()  # 返回是连续的概率\n",
    "\n",
    "# 计算动态阈值\n",
    "def calculate_dynamic_thresholds(bounds):\n",
    "    vertical_distances = []\n",
    "    horizontal_overlaps = []\n",
    "    for i in range(1, len(bounds)):\n",
    "        prev_bound = bounds[i-1]\n",
    "        curr_bound = bounds[i]\n",
    "        vertical_distance = curr_bound[0][0][1] - prev_bound[0][3][1]\n",
    "        horizontal_overlap = max(0, (min(curr_bound[0][1][0], prev_bound[0][1][0]) - max(curr_bound[0][0][0], prev_bound[0][0][0])) / \\\n",
    "                             min(curr_bound[0][1][0] - curr_bound[0][0][0], prev_bound[0][1][0] - prev_bound[0][0][0]))\n",
    "        vertical_distances.append(vertical_distance)\n",
    "        horizontal_overlaps.append(horizontal_overlap)\n",
    "    \n",
    "    vertical_threshold = np.percentile(vertical_distances, 70)  # 动态计算70百分位垂直距离作为阈值\n",
    "    horizontal_threshold = np.percentile(horizontal_overlaps, 10)  # 动态计算10百分位水平重叠作为阈值\n",
    "    return vertical_threshold, horizontal_threshold\n",
    "\n",
    "# 获取动态阈值\n",
    "vertical_threshold, horizontal_threshold = calculate_dynamic_thresholds(bounds)\n",
    "\n",
    "# 初步合并文本块\n",
    "def initial_merge(bounds, vertical_threshold, horizontal_threshold, paragraph_threshold=1.5):\n",
    "    merged_bounds = []  # 存放初步合并后的文本框\n",
    "    for bound in bounds:\n",
    "        if len(merged_bounds) == 0:\n",
    "            merged_bounds.append(bound)\n",
    "        else:\n",
    "            last_bound = merged_bounds[-1]\n",
    "            vertical_distance = bound[0][0][1] - last_bound[0][3][1]\n",
    "            horizontal_overlap = max(0, (min(bound[0][1][0], last_bound[0][1][0]) - max(bound[0][0][0], last_bound[0][0][0])) / \\\n",
    "                                 min(bound[0][1][0] - bound[0][0][0], last_bound[0][1][0] - last_bound[0][0][0]))\n",
    "\n",
    "            if vertical_distance < vertical_threshold * paragraph_threshold and horizontal_overlap > horizontal_threshold:\n",
    "                new_bound = [\n",
    "                    [min(bound[0][0][0], last_bound[0][0][0]), min(bound[0][0][1], last_bound[0][0][1])],  # 左上角\n",
    "                    [max(bound[0][1][0], last_bound[0][1][0]), min(bound[0][1][1], last_bound[0][1][1])],  # 右上角\n",
    "                    [max(bound[0][2][0], last_bound[0][2][0]), max(bound[0][2][1], last_bound[0][2][1])],  # 右下角\n",
    "                    [min(bound[0][3][0], last_bound[0][3][0]), max(bound[0][3][1], last_bound[0][3][1])]   # 左下角\n",
    "                ]\n",
    "                new_text = last_bound[1] + ' ' + bound[1]\n",
    "                merged_bounds[-1] = (new_bound, new_text, bound[2])\n",
    "            else:\n",
    "                merged_bounds.append(bound)\n",
    "    return merged_bounds\n",
    "\n",
    "# 基于BERT模型进一步合并文本块\n",
    "def refine_merge(merged_bounds, nsp_threshold=0.7, similarity_threshold=0.8):\n",
    "  refined_bounds = []  # 存放进一步合并后的文本框\n",
    "  for current_bound in merged_bounds:\n",
    "    closest_next_bound = None\n",
    "    closest_vertical_distance = float('inf')\n",
    "    for next_bound in merged_bounds[merged_bounds.index(current_bound) + 1:]:\n",
    "      # Check for horizontal overlap\n",
    "      if current_bound[0][0][0] <= next_bound[0][1][0] and next_bound[0][0][0] <= current_bound[0][1][0]:\n",
    "        vertical_distance = next_bound[0][0][1] - current_bound[0][3][1]\n",
    "        if vertical_distance >= 0 and vertical_distance < closest_vertical_distance:\n",
    "          closest_next_bound = next_bound\n",
    "          closest_vertical_distance = vertical_distance\n",
    "\n",
    "    if closest_next_bound and should_merge(current_bound[1], closest_next_bound[1], nsp_threshold, similarity_threshold):\n",
    "      new_bound = [\n",
    "          [min(current_bound[0][0][0], closest_next_bound[0][0][0]), min(current_bound[0][0][1], closest_next_bound[0][0][1])],\n",
    "          [max(current_bound[0][1][0], closest_next_bound[0][1][0]), min(current_bound[0][1][1], closest_next_bound[0][1][1])],\n",
    "          [max(current_bound[0][2][0], closest_next_bound[0][2][0]), max(current_bound[0][2][1], closest_next_bound[0][2][1])],\n",
    "          [min(current_bound[0][3][0], closest_next_bound[0][3][0]), max(current_bound[0][3][1], closest_next_bound[0][3][1])]\n",
    "      ]\n",
    "      new_text = current_bound[1] + ' ' + closest_next_bound[1]\n",
    "      refined_bounds.append((new_bound, new_text, closest_next_bound[2]))\n",
    "    else:\n",
    "      refined_bounds.append(current_bound)\n",
    "  return refined_bounds\n",
    "\n",
    "# 判断是否合并\n",
    "def should_merge(sentence_a, sentence_b, nsp_threshold=0.7, similarity_threshold=0.8):\n",
    "    nsp_prob = nsp_predict(sentence_a, sentence_b)\n",
    "    embedding_a = get_sentence_embedding(sentence_a)\n",
    "    embedding_b = get_sentence_embedding(sentence_b)\n",
    "    similarity = cosine_similarity([embedding_a], [embedding_b])[0][0]\n",
    "    \n",
    "    return nsp_prob > nsp_threshold or similarity > similarity_threshold\n",
    "\n",
    "# 初步合并\n",
    "merged_bounds = initial_merge(bounds, vertical_threshold, horizontal_threshold)\n",
    "\n",
    "# 进一步合并\n",
    "refined_bounds = refine_merge(merged_bounds)\n",
    "\n",
    "# 定义绘制边界框的函数\n",
    "def draw_boxes(image, bounds, color='blue', width=4):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for bound in bounds:\n",
    "        p0, p1, p2, p3 = bound[0]\n",
    "        draw.line([*p0, *p1, *p2, *p3, *p0], fill=color, width=width)\n",
    "    return image\n",
    "\n",
    "# 在图像上绘制边界框\n",
    "draw_boxes(images, merged_bounds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
